{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14_dog_cat_classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinajordan/DS-Training/blob/master/14_dog_cat_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC4_Z-jWZBLU",
        "colab_type": "text"
      },
      "source": [
        "# Dogs vs Cats CNN Classifier\n",
        "\n",
        "\n",
        "Today we are following along Chapter 5 Section 2 of Deep Learning with Python. One can also follow along this example from Francois Chollet on the Keras blog: \n",
        "\n",
        "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
        "\n",
        "**Please Ensure your Runtime is set to GPU for this notebook.**\n",
        "\n",
        "\n",
        "First:\n",
        "Connect to Kaggle and Download Dog_Cat Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bblQZQzwWBjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import itertools\n",
        "from PIL import Image\n",
        "from IPython.core import display as ICD\n",
        "%matplotlib inline\n",
        "def convert_to_df(csv): # needs to be repaired\n",
        "    df = pd.DataFrame(data=csv)[0].str.split(',',expand=True)  \n",
        "    header = df.iloc[0]\n",
        "    df = df[1:]\n",
        "    df.columns = header\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzknToJSY4-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USER_ID = 'kevinajordan' # REPLACE WITH YOUR OWN USER NAME\n",
        "USER_SECRET = 'xxxxxxxx' # REPLACE WITH YOUR OWN PRIVATE API TOKEN\n",
        "import os, json, nbformat, pandas as pd\n",
        "KAGGLE_CONFIG_DIR = os.path.join(os.path.expandvars('$HOME'), '.kaggle')\n",
        "os.makedirs(KAGGLE_CONFIG_DIR, exist_ok = True)\n",
        "with open(os.path.join(KAGGLE_CONFIG_DIR, 'kaggle.json'), 'w') as f:\n",
        "    json.dump({'username': USER_ID, 'key': USER_SECRET}, f)\n",
        "!chmod 600 {KAGGLE_CONFIG_DIR}/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJx-sErBx_bL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dogs_cats_search_csv = !kaggle datasets list -s dogs-vs-cats --csv\n",
        "dogs_cats_df = convert_to_df(dogs_cats_search_csv)\n",
        "print(\"Search Results for Dogs vs Cats\")\n",
        "ICD.display(dogs_cats_df.head(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9St11uhaGc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d biaiscience/dogs-vs-cats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWZbOCMBICLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip dogs-vs-cats.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUFcghp0n95t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -d data/ train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIWNhU53rOvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -d data/ test.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4NJl3fQrTR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('data')\n",
        "print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2ZyVxgwPhUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "\n",
        "train_dir = ('train')\n",
        "os.mkdir('validation')\n",
        "validation_dir = ('validation')\n",
        "test_dir = ('test')\n",
        "os.mkdir('test')\n",
        "\n",
        "train_cats_dir = ('train/cats')\n",
        "os.mkdir(train_cats_dir)\n",
        "\n",
        "train_dogs_dir = ('train/dogs')\n",
        "os.mkdir(train_dogs_dir)\n",
        "\n",
        "validation_cats_dir = ('validation/cats')\n",
        "os.mkdir(validation_cats_dir)\n",
        "\n",
        "validation_dogs_dir = ('validation/dogs')\n",
        "os.mkdir(validation_dogs_dir)\n",
        "\n",
        "test_cats_dir = ('test/cats')\n",
        "os.mkdir(test_cats_dir)\n",
        "\n",
        "test_dogs_dir = ('test/dogs')\n",
        "os.mkdir(test_dogs_dir)\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(6250)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(train_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(6250, 9500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(train_dir, fname)\n",
        "    dst = os.path.join(validation_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(9500, 12500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(train_dir, fname)\n",
        "    dst = os.path.join(test_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(6250)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(train_dir, fname)\n",
        "    dst = os.path.join(train_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(6250, 9500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(train_dir, fname)\n",
        "    dst = os.path.join(validation_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(9500, 12500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(train_dir, fname)\n",
        "    dst = os.path.join(test_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWsCFGzuONyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
        "\n",
        "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
        "\n",
        "print('total test dog images:', len(os.listdir(test_dogs_dir)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYX77D7-tG4X",
        "colab_type": "text"
      },
      "source": [
        "## Training Convnets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98x9D2GqJSfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models, layers\n",
        "\n",
        "# Initiate a sequential model\n",
        "____\n",
        "\n",
        "# add the 4 conv layers with maxpooling (2x2 kernel) in between.\n",
        "# 1st layer - 32 nodes, 2nd layer - 64 nodes, 3rd and 4th layers - 128 nodes\n",
        "_____\n",
        "\n",
        "\n",
        "# Before feeding to a dense layer, you need to flatten your feature map from 3D to 1D.\n",
        "_____\n",
        "\n",
        "# Add two fully connected layers. the output layer should have an activation value appropriate for binary classification\n",
        "# 1st dense layer - 512 nodes\n",
        "_____\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9RVK7EOsQiq",
        "colab_type": "text"
      },
      "source": [
        "<!--\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "# Initiate a sequential model \n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbYV_L_BJZ3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print out your model architecture and summary\n",
        "_____"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZltfsOxPTOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile your model with a loss function appropriate for binary classification, and a learning rate of 1e-4.\n",
        "_______"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8lnQTo2uZLa",
        "colab_type": "text"
      },
      "source": [
        "<!--\n",
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])[link text](https://)\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f68yl-kMy3Bq",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing\n",
        "As you know by now, data should be formatted into appropriately preprocessed floating-point tensors before being fed into the network. Currently, the data sits on a drive as JPEG files, so the steps for getting it into the network are roughly as follows:\n",
        "\n",
        "* Read the picture files.\n",
        "* Decode the JPEG content to RGB grids of pixels.\n",
        "* Convert these into floating-point tensors.\n",
        "* Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6AD3W3SKP9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the ImageDataGenerator module from keras\n",
        "________\n",
        "\n",
        "# Initiate the ImageDataGenerator with rescaling set to 1./255 for both the train and test data.\n",
        "\n",
        "train_datagen = _______\n",
        "test_datagen = _______\n",
        "\n",
        "# Generate training samples using the datagen variables you just created and pulling from the train data and validation data.\n",
        "train_generator = train_datagen._____(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen._____(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKgwea-6ic5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "  print('data batch shape:', data_batch.shape)\n",
        "  print('labels batch shape:', labels_batch.shape)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIfmbswbiqQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train your model on the small sample of data stored stored in your generators\n",
        "history = model.______(\n",
        "      _______,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_data=_____,\n",
        "      validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skr9EW6VkJqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save your model in a h5 file\n",
        "model._____('______')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHciRPFolNqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGXHbrO8ldmq",
        "colab_type": "text"
      },
      "source": [
        "These plots are characteristic of overfitting. The training accuracy increases linearly over time, until it reaches nearly 100%, whereas the validation accuracy stalls at 70–72%. The validation loss reaches its minimum after only five epochs and then stalls, whereas the training loss keeps decreasing linearly until it reaches nearly 0.\n",
        "\n",
        "Because you have relatively few training samples (2,000), overfitting will be your number-one concern. You already know about a number of techniques that can help mitigate overfitting, such as dropout and weight decay (L2 regularization). We’re now going to work with a new one, specific to computer vision and used almost universally when processing images with deep-learning models: data augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O342xFtj1gfz",
        "colab_type": "text"
      },
      "source": [
        "## Data Augmentation\n",
        "\n",
        "In order to make the most of our few training examples, we will \"augment\" them via a number of random transformations, so that our model would never see twice the exact same picture. This helps prevent overfitting and helps the model generalize better.\n",
        "\n",
        "In Keras this can be done via the keras.preprocessing.image.ImageDataGenerator class. This class allows you to:\n",
        "\n",
        "* configure random transformations and normalization operations to be done on your image data during training\n",
        "* instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory). \n",
        "\n",
        "These generators can then be used with the Keras model methods that accept data generators as inputs, fit_generator, evaluate_generator and predict_generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVoZVTV21d6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_McbaTDunvTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "fnames = [os.path.join(train_cats_dir, fname) for\n",
        "     fname in os.listdir(train_cats_dir)]\n",
        "\n",
        "img_path = fnames[3]\n",
        "\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "x = x.reshape((1,) + x.shape)\n",
        "\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1):\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i % 4 == 0:\n",
        "        break\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjgQImssn8sD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjqR4Ahqcn_v",
        "colab_type": "text"
      },
      "source": [
        "<!--\n",
        "train_datagen = _______(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi7VxQNJoAgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the ImageDataGenerator to rescale between 1./255, rotation of 40 degrees, shift width and height by 0.2, same for shear and zoom range, and do a horizontal flip\n",
        "train_datagen = _______()\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCqd7stooRI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('cats_and_dogs_small_2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}